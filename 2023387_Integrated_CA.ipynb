{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "342b25f5",
   "metadata": {},
   "source": [
    "# E-Discovery with Neural Network\n",
    "## BigData Processing\n",
    "### Hadoop / PySpark \n",
    "\n",
    "Dataset zip file - https://www.cs.cmu.edu/~enron/enron_mail_20150507.tar.gz\n",
    "Dataset License - https://www.cs.cmu.edu/~enron/\n",
    "\n",
    "Commands to be include in the Linux Terminal in order to start Hadoop and PySpark\n",
    "\n",
    "$start-dfs.sh\n",
    "\n",
    "$start-yarn.sh\n",
    "\n",
    "$pyspark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa906bd1",
   "metadata": {},
   "source": [
    "### PySpark reading a file form a CSV\n",
    "Firstly, necessary modules are imported to enable Spark operations, handle string data, and work with regular expressions. To ensure a smooth experience, warnings from the Python code will be suppressed, meaning they won't interrupt or clutter the output.\n",
    "\n",
    "Following the preparation, a Spark session is initiated. Think of this session as the starting point for all Spark operations. It's named \"EmailDataPrep\" to reflect its purpose: preparing email data for analysis or further processing.\n",
    "\n",
    "Finally, it leads to reading the data. The CSV file located in a distributed file system (HDFS) will be read into a DataFrame. A DataFrame is a table of data with rows and columns, where the data can be manipulated and analyzed. The reading process is designed to recognize the first row as column names (header=True) and automatically deduce the type of data in each column (inferSchema=True). This step concludes the initial data loading, setting the stage for subsequent data manipulation and analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e35c80bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating required modules\n",
    "from pyspark.sql import SparkSession  # Essential for Spark operations\n",
    "from pyspark.sql.functions import udf  # User Defined Functions\n",
    "from pyspark.sql.types import StringType  # Data type for string operations\n",
    "import re  # Regular expressions library\n",
    "\n",
    "# Handling warnings\n",
    "import warnings  # Importing warnings library\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress all warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb90175a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/01 19:27:15 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Setting up the Spark Session\n",
    "spark = SparkSession.builder.appName(\"EmailDataPrep\").getOrCreate()\n",
    "\n",
    "# Reading the data\n",
    "df = spark.read.csv(\"hdfs:///user1/emails.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45c1795",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA) / Data Inspection\n",
    "This section focuses on Exploratory Data Analysis (EDA) and data inspection using PySpark, a tool for handling big data. The aim is to understand the data better by performing initial checks and summaries. \n",
    "\n",
    "Through these steps, the data is initially assessed to guide further detailed analysis and decision-making for cleaning, transforming, and analyzing the data effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17c7b6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                file|             message|\n",
      "+--------------------+--------------------+\n",
      "|allen-p/_sent_mai...|Message-ID: <1878...|\n",
      "|           Date: Mon| 14 May 2001 16:3...|\n",
      "|From: phillip.all...|                null|\n",
      "|To: tim.belden@en...|                null|\n",
      "|           Subject: |                null|\n",
      "|   Mime-Version: 1.0|                null|\n",
      "|Content-Type: tex...|                null|\n",
      "|Content-Transfer-...|                null|\n",
      "|X-From: Phillip K...|                null|\n",
      "|X-To: Tim Belden ...|                null|\n",
      "+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview the initial rows of the DataFrame\n",
    "df.show(n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77b617ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- file: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Output the structure and data types of the DataFrame\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6c4d9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------+\n",
      "|summary|                file| message|\n",
      "+-------+--------------------+--------+\n",
      "|  count|             8299853| 2508249|\n",
      "|   mean|                 NaN|Infinity|\n",
      "| stddev|                 NaN|     NaN|\n",
      "|    min|                  \\t|      \\t|\n",
      "|    max|~~~~~~~~~~~~~~~~~...|       ||\n",
      "+-------+--------------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Obtain and display descriptive statistics for columns with numerical data\n",
    "df.describe().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2150167",
   "metadata": {},
   "source": [
    "### Data Cleaning / Text Preprocessing\n",
    "This section is about cleaning the data and preparing text for analysis. Data often comes with issues like missing information, inconsistencies, and unnecessary details that can affect analysis. Here's how the process unfolds:\n",
    "\n",
    "Through these steps, the dataset is refined and prepared, setting a solid foundation for subsequent analysis or machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98648c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------+-------------------------------------------------+\n",
      "|file                                          |message                                          |\n",
      "+----------------------------------------------+-------------------------------------------------+\n",
      "|allen-p/_sent_mail/1.                         |messageid 187829811075855378110javamailevansthyme|\n",
      "|Date: Mon                                     |14 may 2001 163900 0700 pdt                      |\n",
      "|From: phillip.allen@enron.com                 |                                                 |\n",
      "|To: tim.belden@enron.com                      |                                                 |\n",
      "|Subject:                                      |                                                 |\n",
      "|Mime-Version: 1.0                             |                                                 |\n",
      "|Content-Type: text/plain; charset=us-ascii    |                                                 |\n",
      "|Content-Transfer-Encoding: 7bit               |                                                 |\n",
      "|X-From: Phillip K Allen                       |                                                 |\n",
      "|X-To: Tim Belden <Tim Belden/Enron@EnronXGate>|                                                 |\n",
      "|X-cc:                                         |                                                 |\n",
      "|X-bcc:                                        |                                                 |\n",
      "|X-Folder: \\Phillip_Allen_Jan2002_1\\Allen      |phillip ksent mail                               |\n",
      "|X-Origin: Allen-P                             |                                                 |\n",
      "|X-FileName: pallen (Non-Privileged).pst       |                                                 |\n",
      "|Here is our forecast                          |                                                 |\n",
      "| \"                                            |                                                 |\n",
      "|allen-p/_sent_mail/10.                        |messageid 154649861075855378456javamailevansthyme|\n",
      "|Date: Fri                                     |4 may 2001 135100 0700 pdt                       |\n",
      "|From: phillip.allen@enron.com                 |                                                 |\n",
      "+----------------------------------------------+-------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 6:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Addressing Missing Information\n",
    "# Replace any missing values in the dataset with an empty string.\n",
    "df = df.fillna('')\n",
    "\n",
    "# Defining a Function for Text Cleanup\n",
    "def clean_text(text):\n",
    "    # Return an empty string if the input text is missing.\n",
    "    if text is None:\n",
    "        return ''\n",
    "    # Change all characters in the text to lowercase for uniformity.\n",
    "    text = text.lower()\n",
    "    # Eliminate lines that resemble email headers or unneeded metadata.\n",
    "    text = re.sub(r'^[a-z]+:.*$', '', text)  # Finds and removes lines starting with certain patterns.\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Collapses multiple spaces into a single space.\n",
    "    # Remove characters that are not letters, numbers, or spaces.\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    # Trim leading or trailing spaces from the text.\n",
    "    return text.strip()\n",
    "\n",
    "# Making the Text Cleanup Function Available\n",
    "clean_text_udf = udf(clean_text, StringType())\n",
    "\n",
    "# Cleaning Text in the 'message' Column of the Dataset\n",
    "df = df.withColumn('message', clean_text_udf(df['message']))\n",
    "\n",
    "# Displaying the Processed Data for Review\n",
    "df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be62123d",
   "metadata": {},
   "source": [
    "### Feature Engineering and Vectorization\n",
    "This section focuses on Feature Engineering and Vectorization, essential steps in preparing text data for machine learning models. The goal is to transform the text from the 'message' column of a DataFrame into a numerical format that a machine learning model can understand.\n",
    "\n",
    "By converting text into numerical features through these steps, the data is now ready to be used in machine learning models for tasks like classification, clustering, or sentiment analysis. This process of feature engineering and vectorization is crucial for extracting meaningful information from text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9aebe68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "|message                                          |features                                                                                                         |\n",
      "+-------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "|messageid 187829811075855378110javamailevansthyme|(20,[12,14],[0.2628853782003786,3.435649098139253])                                                              |\n",
      "|14 may 2001 163900 0700 pdt                      |(20,[0,1,5,12],[6.620332160461084,6.1845443249149366,3.2725815853775964,0.2628853782003786])                     |\n",
      "|                                                 |(20,[12],[0.2628853782003786])                                                                                   |\n",
      "|                                                 |(20,[12],[0.2628853782003786])                                                                                   |\n",
      "|                                                 |(20,[12],[0.2628853782003786])                                                                                   |\n",
      "|                                                 |(20,[12],[0.2628853782003786])                                                                                   |\n",
      "|                                                 |(20,[12],[0.2628853782003786])                                                                                   |\n",
      "|                                                 |(20,[12],[0.2628853782003786])                                                                                   |\n",
      "|                                                 |(20,[12],[0.2628853782003786])                                                                                   |\n",
      "|                                                 |(20,[12],[0.2628853782003786])                                                                                   |\n",
      "|                                                 |(20,[12],[0.2628853782003786])                                                                                   |\n",
      "|                                                 |(20,[12],[0.2628853782003786])                                                                                   |\n",
      "|phillip ksent mail                               |(20,[0,15,19],[3.310166080230542,3.1561953469191426,3.4951592584960713])                                         |\n",
      "|                                                 |(20,[12],[0.2628853782003786])                                                                                   |\n",
      "|                                                 |(20,[12],[0.2628853782003786])                                                                                   |\n",
      "|                                                 |(20,[12],[0.2628853782003786])                                                                                   |\n",
      "|                                                 |(20,[12],[0.2628853782003786])                                                                                   |\n",
      "|messageid 154649861075855378456javamailevansthyme|(20,[9,12],[3.4676866263660777,0.2628853782003786])                                                              |\n",
      "|4 may 2001 135100 0700 pdt                       |(20,[0,1,5,10,12],[3.310166080230542,6.1845443249149366,3.2725815853775964,3.375870274412286,0.2628853782003786])|\n",
      "|                                                 |(20,[12],[0.2628853782003786])                                                                                   |\n",
      "+-------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "def add_text_features(dataframe):\n",
    "    \"\"\"\n",
    "    Enhances a DataFrame by analyzing text in the 'message' column and adding a 'features' column.\n",
    "    This 'features' column represents text as numerical data useful for machine learning.\n",
    "    \n",
    "    Parameter:\n",
    "    - dataframe: A DataFrame that includes a 'message' column with text.\n",
    "    \n",
    "    Output:\n",
    "    - A DataFrame that now includes a 'features' column with text analyzed into TF-IDF vectors.\n",
    "    \"\"\"\n",
    "    # First, break text into individual words.\n",
    "    tokenizer = Tokenizer(inputCol=\"message\", outputCol=\"words\")\n",
    "    \n",
    "    # Second, filter out common, less meaningful words (like 'the', 'a').\n",
    "    remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "    \n",
    "    # Third, count how frequently each word appears and represent this as numerical data.\n",
    "    hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=20)\n",
    "    \n",
    "    # Fourth, assess the importance of a word based on how frequently it appears across all messages.\n",
    "    idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "    \n",
    "    # Chain these steps into a process to be applied.\n",
    "    pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf])\n",
    "    \n",
    "    # Execute the process on the provided data.\n",
    "    model = pipeline.fit(dataframe)\n",
    "    \n",
    "    # Apply the transformations to the DataFrame.\n",
    "    result = model.transform(dataframe)\n",
    "    \n",
    "    # The modified DataFrame is returned, now with a 'features' column.\n",
    "    return result\n",
    "\n",
    "# Example of applying this function to a DataFrame 'df' that contains a 'message' column.\n",
    "enhanced_df = add_text_features(df)\n",
    "\n",
    "# Display the original messages and their corresponding numerical representations.\n",
    "enhanced_df.select('message', 'features').show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f277c1ab",
   "metadata": {},
   "source": [
    "### Design and Training - ANN Model\n",
    "This section is dedicated to designing and training an Artificial Neural Network (ANN) model for binary classification tasks. The process involves using Keras, a high-level neural networks API, which runs on top of TensorFlow, a powerful open-source software library for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e5c2fb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 19:28:33.368913: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-01 19:28:33.724311: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-01 19:28:33.724394: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-01 19:28:33.786416: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-01 19:28:33.926642: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-01 19:28:33.927914: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-01 19:28:35.272199: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 8ms/step - loss: 0.7035 - accuracy: 0.5013 - val_loss: 0.6944 - val_accuracy: 0.5050\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7017 - accuracy: 0.5275 - val_loss: 0.6891 - val_accuracy: 0.5400\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6956 - accuracy: 0.5312 - val_loss: 0.6945 - val_accuracy: 0.5150\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6954 - accuracy: 0.5263 - val_loss: 0.6909 - val_accuracy: 0.5100\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6955 - accuracy: 0.5063 - val_loss: 0.6934 - val_accuracy: 0.5050\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6884 - accuracy: 0.5462 - val_loss: 0.6939 - val_accuracy: 0.5100\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6920 - accuracy: 0.5288 - val_loss: 0.6918 - val_accuracy: 0.5150\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.5450 - val_loss: 0.6935 - val_accuracy: 0.5200\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.5275 - val_loss: 0.6928 - val_accuracy: 0.5150\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.5500 - val_loss: 0.6940 - val_accuracy: 0.5200\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6848 - accuracy: 0.5437 - val_loss: 0.6911 - val_accuracy: 0.5250\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6856 - accuracy: 0.5425 - val_loss: 0.6922 - val_accuracy: 0.5200\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6785 - accuracy: 0.5725 - val_loss: 0.6941 - val_accuracy: 0.5150\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6868 - accuracy: 0.5487 - val_loss: 0.6936 - val_accuracy: 0.5150\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.6800 - accuracy: 0.5788 - val_loss: 0.6914 - val_accuracy: 0.5250\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6828 - accuracy: 0.5663 - val_loss: 0.6942 - val_accuracy: 0.5150\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6837 - accuracy: 0.5700 - val_loss: 0.6917 - val_accuracy: 0.5400\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6812 - accuracy: 0.5800 - val_loss: 0.6936 - val_accuracy: 0.5250\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6757 - accuracy: 0.5825 - val_loss: 0.6926 - val_accuracy: 0.5350\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6800 - accuracy: 0.5713 - val_loss: 0.6964 - val_accuracy: 0.5350\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6826 - accuracy: 0.5500 - val_loss: 0.6947 - val_accuracy: 0.5450\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6758 - accuracy: 0.5888 - val_loss: 0.6949 - val_accuracy: 0.5500\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6770 - accuracy: 0.5738 - val_loss: 0.6922 - val_accuracy: 0.5450\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6698 - accuracy: 0.5900 - val_loss: 0.6909 - val_accuracy: 0.5300\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6729 - accuracy: 0.5875 - val_loss: 0.6931 - val_accuracy: 0.5250\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.5725 - val_loss: 0.6915 - val_accuracy: 0.5150\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6784 - accuracy: 0.5638 - val_loss: 0.6936 - val_accuracy: 0.5150\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6705 - accuracy: 0.5788 - val_loss: 0.6992 - val_accuracy: 0.5350\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.6100 - val_loss: 0.6947 - val_accuracy: 0.5250\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6748 - accuracy: 0.6087 - val_loss: 0.6968 - val_accuracy: 0.5150\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6680 - accuracy: 0.6037 - val_loss: 0.6984 - val_accuracy: 0.5150\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.5888 - val_loss: 0.6960 - val_accuracy: 0.5350\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6623 - accuracy: 0.5925 - val_loss: 0.6977 - val_accuracy: 0.5150\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6647 - accuracy: 0.5962 - val_loss: 0.6988 - val_accuracy: 0.5050\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6652 - accuracy: 0.5987 - val_loss: 0.6998 - val_accuracy: 0.5050\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6695 - accuracy: 0.5888 - val_loss: 0.7016 - val_accuracy: 0.5300\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6682 - accuracy: 0.5838 - val_loss: 0.6951 - val_accuracy: 0.5150\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6665 - accuracy: 0.6050 - val_loss: 0.7013 - val_accuracy: 0.4900\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6570 - accuracy: 0.6137 - val_loss: 0.6993 - val_accuracy: 0.5150\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6542 - accuracy: 0.6200 - val_loss: 0.7048 - val_accuracy: 0.5100\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6581 - accuracy: 0.6012 - val_loss: 0.7017 - val_accuracy: 0.5100\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6526 - accuracy: 0.6212 - val_loss: 0.7058 - val_accuracy: 0.5100\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6647 - accuracy: 0.5975 - val_loss: 0.7009 - val_accuracy: 0.5050\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6542 - accuracy: 0.6225 - val_loss: 0.7002 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6552 - accuracy: 0.6237 - val_loss: 0.7049 - val_accuracy: 0.5200\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6585 - accuracy: 0.5975 - val_loss: 0.7022 - val_accuracy: 0.5400\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6527 - accuracy: 0.6137 - val_loss: 0.7021 - val_accuracy: 0.5150\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.6513 - val_loss: 0.7047 - val_accuracy: 0.5150\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6417 - accuracy: 0.6288 - val_loss: 0.7041 - val_accuracy: 0.5100\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.6250 - val_loss: 0.7098 - val_accuracy: 0.5250\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6515 - accuracy: 0.6025 - val_loss: 0.6994 - val_accuracy: 0.4850\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6657 - accuracy: 0.6150 - val_loss: 0.7029 - val_accuracy: 0.5150\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6536 - accuracy: 0.6275 - val_loss: 0.7016 - val_accuracy: 0.5150\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6557 - accuracy: 0.6037 - val_loss: 0.7037 - val_accuracy: 0.5150\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.6450 - val_loss: 0.7021 - val_accuracy: 0.5150\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6370 - accuracy: 0.6275 - val_loss: 0.7003 - val_accuracy: 0.5050\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6385 - accuracy: 0.6338 - val_loss: 0.7091 - val_accuracy: 0.5300\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6315 - accuracy: 0.6388 - val_loss: 0.7050 - val_accuracy: 0.5100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6392 - accuracy: 0.6300 - val_loss: 0.7058 - val_accuracy: 0.5050\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.6413 - val_loss: 0.7049 - val_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6424 - accuracy: 0.6400 - val_loss: 0.7028 - val_accuracy: 0.5050\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6296 - accuracy: 0.6500 - val_loss: 0.7070 - val_accuracy: 0.5100\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6351 - accuracy: 0.6400 - val_loss: 0.7065 - val_accuracy: 0.4900\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6304 - accuracy: 0.6538 - val_loss: 0.7104 - val_accuracy: 0.4950\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6172 - accuracy: 0.6538 - val_loss: 0.7065 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6394 - accuracy: 0.6550 - val_loss: 0.7044 - val_accuracy: 0.5150\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6166 - accuracy: 0.6562 - val_loss: 0.7105 - val_accuracy: 0.4950\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6163 - accuracy: 0.6687 - val_loss: 0.7121 - val_accuracy: 0.5200\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.6600 - val_loss: 0.7112 - val_accuracy: 0.5250\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6188 - accuracy: 0.6750 - val_loss: 0.7158 - val_accuracy: 0.5200\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6268 - accuracy: 0.6425 - val_loss: 0.7158 - val_accuracy: 0.5250\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6281 - accuracy: 0.6475 - val_loss: 0.7145 - val_accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6161 - accuracy: 0.6687 - val_loss: 0.7192 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6154 - accuracy: 0.6538 - val_loss: 0.7185 - val_accuracy: 0.5100\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6046 - accuracy: 0.6875 - val_loss: 0.7279 - val_accuracy: 0.5400\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6080 - accuracy: 0.6800 - val_loss: 0.7214 - val_accuracy: 0.5100\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6175 - accuracy: 0.6463 - val_loss: 0.7218 - val_accuracy: 0.5200\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6268 - accuracy: 0.6413 - val_loss: 0.7258 - val_accuracy: 0.5150\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6196 - accuracy: 0.6637 - val_loss: 0.7281 - val_accuracy: 0.5050\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6150 - accuracy: 0.6675 - val_loss: 0.7262 - val_accuracy: 0.5350\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6122 - accuracy: 0.6600 - val_loss: 0.7187 - val_accuracy: 0.5300\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6070 - accuracy: 0.6737 - val_loss: 0.7225 - val_accuracy: 0.5200\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6135 - accuracy: 0.6538 - val_loss: 0.7180 - val_accuracy: 0.5150\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6099 - accuracy: 0.6450 - val_loss: 0.7230 - val_accuracy: 0.5200\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6100 - accuracy: 0.6787 - val_loss: 0.7297 - val_accuracy: 0.5150\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6054 - accuracy: 0.6750 - val_loss: 0.7256 - val_accuracy: 0.5150\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.6725 - val_loss: 0.7424 - val_accuracy: 0.5150\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5974 - accuracy: 0.6888 - val_loss: 0.7268 - val_accuracy: 0.5200\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.6900 - val_loss: 0.7254 - val_accuracy: 0.5250\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6071 - accuracy: 0.6650 - val_loss: 0.7250 - val_accuracy: 0.5350\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6059 - accuracy: 0.6775 - val_loss: 0.7309 - val_accuracy: 0.5350\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6108 - accuracy: 0.6413 - val_loss: 0.7260 - val_accuracy: 0.5250\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5992 - accuracy: 0.6662 - val_loss: 0.7309 - val_accuracy: 0.5200\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6012 - accuracy: 0.6675 - val_loss: 0.7267 - val_accuracy: 0.5150\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6044 - accuracy: 0.6562 - val_loss: 0.7207 - val_accuracy: 0.5400\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5851 - accuracy: 0.6988 - val_loss: 0.7252 - val_accuracy: 0.5200\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6054 - accuracy: 0.6538 - val_loss: 0.7319 - val_accuracy: 0.5350\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5959 - accuracy: 0.6850 - val_loss: 0.7333 - val_accuracy: 0.5350\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5876 - accuracy: 0.7113 - val_loss: 0.7441 - val_accuracy: 0.5200\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5938 - accuracy: 0.6950 - val_loss: 0.7405 - val_accuracy: 0.5200\n",
      "Training Completed.\n",
      "Model saved as model_saved.h5.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, save_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def build_neural_network(input_features):\n",
    "    \"\"\"\n",
    "    Prepares a neural network model with a basic configuration.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(64, input_dim=input_features, activation='relu'),  # Layer with 64 neurons\n",
    "        Dropout(0.5),  # Helps reduce overfitting\n",
    "        Dense(32, activation='relu'),  # Another layer for deeper understanding\n",
    "        Dense(1, activation='sigmoid')  # Final layer for binary classification\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate_model(features, labels, input_feature_count, epochs=100, batch_size=32, validation_split=0.2):\n",
    "    \"\"\"\n",
    "    Trains the neural network and evaluates it on a validation set.\n",
    "    \"\"\"\n",
    "    # Splitting the dataset for training and validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=validation_split, random_state=42)\n",
    "    \n",
    "    # Getting the model ready\n",
    "    model = build_neural_network(input_feature_count)\n",
    "    \n",
    "    # Training starts\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "                        validation_data=(X_val, y_val), verbose=1)\n",
    "    \n",
    "    print(\"Training Completed.\")\n",
    "    \n",
    "    # Saving the model for later use\n",
    "    model.save(\"model_saved.h5\")\n",
    "    print(\"Model saved as model_saved.h5.\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# Sample data for testing\n",
    "demo_features = np.random.rand(1000, 20)  # Random features for 1000 samples\n",
    "demo_labels = np.random.randint(2, size=(1000, ))  # Random binary labels\n",
    "\n",
    "# Training the model with the demo data\n",
    "input_features = 20\n",
    "model, history = train_and_evaluate_model(demo_features, demo_labels, input_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "271e5433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "[[0.24020122]\n",
      " [0.3482641 ]\n",
      " [0.64333194]\n",
      " [0.6089555 ]\n",
      " [0.5527947 ]\n",
      " [0.27187073]\n",
      " [0.6124783 ]\n",
      " [0.46348894]\n",
      " [0.52843624]\n",
      " [0.5466175 ]\n",
      " [0.81779903]\n",
      " [0.55148536]\n",
      " [0.59305537]\n",
      " [0.7563306 ]\n",
      " [0.64777005]\n",
      " [0.45746404]\n",
      " [0.49093357]\n",
      " [0.5096719 ]\n",
      " [0.63515174]\n",
      " [0.27387103]\n",
      " [0.42365465]\n",
      " [0.36551982]\n",
      " [0.72464854]\n",
      " [0.52764255]\n",
      " [0.27205002]\n",
      " [0.31066144]\n",
      " [0.29452646]\n",
      " [0.7887645 ]\n",
      " [0.32312873]\n",
      " [0.30851465]\n",
      " [0.33821002]\n",
      " [0.45942336]\n",
      " [0.48208165]\n",
      " [0.42347434]\n",
      " [0.5191333 ]\n",
      " [0.57893395]\n",
      " [0.63141817]\n",
      " [0.2682784 ]\n",
      " [0.3657912 ]\n",
      " [0.61050767]\n",
      " [0.37065303]\n",
      " [0.23606361]\n",
      " [0.36644465]\n",
      " [0.8360838 ]\n",
      " [0.48727325]\n",
      " [0.5914332 ]\n",
      " [0.6418454 ]\n",
      " [0.18247557]\n",
      " [0.5206826 ]\n",
      " [0.48332503]\n",
      " [0.41524348]\n",
      " [0.3782099 ]\n",
      " [0.7205923 ]\n",
      " [0.44178075]\n",
      " [0.4182626 ]\n",
      " [0.41593543]\n",
      " [0.30592602]\n",
      " [0.2837044 ]\n",
      " [0.31775644]\n",
      " [0.5961379 ]\n",
      " [0.26397347]\n",
      " [0.52733064]\n",
      " [0.35573575]\n",
      " [0.4374527 ]\n",
      " [0.4363614 ]\n",
      " [0.30058816]\n",
      " [0.39105335]\n",
      " [0.3117475 ]\n",
      " [0.25128064]\n",
      " [0.48186556]\n",
      " [0.48859042]\n",
      " [0.50664836]\n",
      " [0.41820967]\n",
      " [0.34737128]\n",
      " [0.57444525]\n",
      " [0.4894434 ]\n",
      " [0.7830926 ]\n",
      " [0.43897313]\n",
      " [0.2473888 ]\n",
      " [0.6734182 ]\n",
      " [0.6190426 ]\n",
      " [0.2354701 ]\n",
      " [0.4623164 ]\n",
      " [0.43891788]\n",
      " [0.5565538 ]\n",
      " [0.8009534 ]\n",
      " [0.22670807]\n",
      " [0.48078522]\n",
      " [0.43766555]\n",
      " [0.60713196]\n",
      " [0.4820555 ]\n",
      " [0.47218922]\n",
      " [0.5597288 ]\n",
      " [0.42614275]\n",
      " [0.19586383]\n",
      " [0.45708132]\n",
      " [0.24178064]\n",
      " [0.39089924]\n",
      " [0.44799286]\n",
      " [0.37140188]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "def get_fraud_chance(model_file, data):\n",
    "    \"\"\"\n",
    "    This function takes a path to a trained machine learning model and an array of data,\n",
    "    and it returns the model's estimates of the likelihood that each data point is fraudulent.\n",
    "    \n",
    "    Arguments:\n",
    "    - model_file: The location of the trained model on the disk.\n",
    "    - data: Array of data points that the model will evaluate. This array should be formatted just like the data used to train the model.\n",
    "    \n",
    "    Outcome:\n",
    "    - An array with each data point's estimated fraud likelihood according to the model.\n",
    "    \"\"\"\n",
    "    # Opening the model from the given file\n",
    "    trained_model = load_model(model_file)\n",
    "    \n",
    "    # Making predictions with the model on the provided data\n",
    "    fraud_chances = trained_model.predict(data)\n",
    "    \n",
    "    return fraud_chances\n",
    "\n",
    "# Example: Predicting with a hypothetical model\n",
    "# Setting up variables for demonstration. The real values depend on your specific model and data.\n",
    "sample_count = 100  # Suppose you have 100 pieces of data\n",
    "expected_shape = (20,)  # Suppose each piece of data should have 20 features\n",
    "\n",
    "# Creating random data for the demonstration. In real use, you'd have actual data here.\n",
    "data_samples = np.random.rand(sample_count, *expected_shape)\n",
    "\n",
    "# Calling the function with the model's file path and the sample data\n",
    "predicted_fraud_chances = get_fraud_chance('model_saved.h5', data_samples)\n",
    "\n",
    "# Showing the model's fraud likelihood estimates for the sample data\n",
    "print(predicted_fraud_chances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9692d3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_fraud_chance_with_visualization(model_file, data):\n",
    "    \"\"\"\n",
    "    This function takes a path to a trained machine learning model and an array of data,\n",
    "    and it returns the model's estimates of the likelihood that each data point is fraudulent.\n",
    "    It also visualizes these estimates.\n",
    "    \n",
    "    Arguments:\n",
    "    - model_file: The location of the trained model on the disk.\n",
    "    - data: Array of data points that the model will evaluate. This array should be formatted just like the data used to train the model.\n",
    "    \n",
    "    Outcome:\n",
    "    - A visualization of each data point's estimated fraud likelihood according to the model.\n",
    "    - An array with each data point's estimated fraud likelihood according to the model.\n",
    "    \"\"\"\n",
    "    # Opening the model from the given file\n",
    "    trained_model = load_model(model_file)\n",
    "    \n",
    "    # Making predictions with the model on the provided data\n",
    "    fraud_chances = trained_model.predict(data).flatten()  # Ensuring it's a 1D array for easy plotting\n",
    "    \n",
    "    # Visualizing the fraud chances\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(np.arange(1, len(fraud_chances) + 1), fraud_chances, marker='o', linestyle='-', color='green')\n",
    "    plt.title('Predicted Fraud Likelihood')\n",
    "    plt.xlabel('Data Point')\n",
    "    plt.ylabel('Fraud Likelihood')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return fraud_chances\n",
    "\n",
    "# Example usage:\n",
    "# Assuming data_samples is defined as your input data array\n",
    "predicted_fraud_chances = get_fraud_chance_with_visualization('model_saved.h5', data_samples)\n",
    "\n",
    "# Note: You would replace 'model_saved.h5' with the actual path to your ANN model file,\n",
    "# and ensure `data_samples` is prepared correctly for your model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc87de93",
   "metadata": {},
   "source": [
    "### Design and Training - CNN Model\n",
    "This section introduces the steps for designing and training a Convolutional Neural Network (CNN) model specifically tailored for one-dimensional data, such as sequences or time-series data. CNNs are well-suited for recognizing patterns in spatial or temporal data thanks to their ability to capture local dependencies and scale input features effectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fad46994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 68ms/step - loss: 0.6927 - accuracy: 0.5250 - val_loss: 0.6898 - val_accuracy: 0.5500\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6741 - accuracy: 0.6000 - val_loss: 0.6909 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.7119 - accuracy: 0.5250 - val_loss: 0.7056 - val_accuracy: 0.4500\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6712 - accuracy: 0.6000 - val_loss: 0.7067 - val_accuracy: 0.4500\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6881 - accuracy: 0.5875 - val_loss: 0.7135 - val_accuracy: 0.4500\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6592 - accuracy: 0.6625 - val_loss: 0.7176 - val_accuracy: 0.4000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6185 - accuracy: 0.6750 - val_loss: 0.7171 - val_accuracy: 0.4000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6536 - accuracy: 0.6250 - val_loss: 0.7103 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6613 - accuracy: 0.6125 - val_loss: 0.7095 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6107 - accuracy: 0.7000 - val_loss: 0.7088 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6265 - accuracy: 0.7375 - val_loss: 0.7027 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6180 - accuracy: 0.7000 - val_loss: 0.6987 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6092 - accuracy: 0.7250 - val_loss: 0.7012 - val_accuracy: 0.4500\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5837 - accuracy: 0.8125 - val_loss: 0.7091 - val_accuracy: 0.4500\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5741 - accuracy: 0.8375 - val_loss: 0.7103 - val_accuracy: 0.4500\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5746 - accuracy: 0.8000 - val_loss: 0.7122 - val_accuracy: 0.4000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5949 - accuracy: 0.7875 - val_loss: 0.7164 - val_accuracy: 0.4000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5603 - accuracy: 0.7500 - val_loss: 0.7213 - val_accuracy: 0.4500\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5292 - accuracy: 0.7875 - val_loss: 0.7260 - val_accuracy: 0.4500\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5347 - accuracy: 0.8125 - val_loss: 0.7268 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5157 - accuracy: 0.8375 - val_loss: 0.7273 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4948 - accuracy: 0.8500 - val_loss: 0.7208 - val_accuracy: 0.4000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5106 - accuracy: 0.8250 - val_loss: 0.7247 - val_accuracy: 0.4000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5051 - accuracy: 0.8000 - val_loss: 0.7197 - val_accuracy: 0.4500\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4667 - accuracy: 0.8750 - val_loss: 0.7227 - val_accuracy: 0.4500\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4547 - accuracy: 0.8500 - val_loss: 0.7179 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4740 - accuracy: 0.8500 - val_loss: 0.7213 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4493 - accuracy: 0.8875 - val_loss: 0.7320 - val_accuracy: 0.4000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4515 - accuracy: 0.8625 - val_loss: 0.7490 - val_accuracy: 0.4000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4225 - accuracy: 0.8875 - val_loss: 0.7428 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.3610 - accuracy: 0.9250 - val_loss: 0.7430 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3810 - accuracy: 0.9375 - val_loss: 0.7428 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3403 - accuracy: 0.9625 - val_loss: 0.7549 - val_accuracy: 0.4500\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3830 - accuracy: 0.9000 - val_loss: 0.7592 - val_accuracy: 0.4000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3347 - accuracy: 0.9125 - val_loss: 0.7572 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3424 - accuracy: 0.9125 - val_loss: 0.7562 - val_accuracy: 0.5500\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3417 - accuracy: 0.9375 - val_loss: 0.7698 - val_accuracy: 0.4000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2774 - accuracy: 0.9500 - val_loss: 0.7930 - val_accuracy: 0.4000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2848 - accuracy: 0.9750 - val_loss: 0.7942 - val_accuracy: 0.4000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3110 - accuracy: 0.9375 - val_loss: 0.7815 - val_accuracy: 0.5500\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2547 - accuracy: 0.9500 - val_loss: 0.7792 - val_accuracy: 0.5500\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2501 - accuracy: 0.9375 - val_loss: 0.7957 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2458 - accuracy: 0.9625 - val_loss: 0.8204 - val_accuracy: 0.4000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2631 - accuracy: 0.9250 - val_loss: 0.8207 - val_accuracy: 0.4500\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2395 - accuracy: 0.9750 - val_loss: 0.8084 - val_accuracy: 0.4500\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1924 - accuracy: 0.9875 - val_loss: 0.8188 - val_accuracy: 0.4500\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1847 - accuracy: 0.9875 - val_loss: 0.8275 - val_accuracy: 0.4500\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2021 - accuracy: 0.9750 - val_loss: 0.8391 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2164 - accuracy: 0.9500 - val_loss: 0.8484 - val_accuracy: 0.4500\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1465 - accuracy: 0.9875 - val_loss: 0.8396 - val_accuracy: 0.5500\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1806 - accuracy: 0.9750 - val_loss: 0.8434 - val_accuracy: 0.5500\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1443 - accuracy: 0.9875 - val_loss: 0.8566 - val_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1477 - accuracy: 0.9875 - val_loss: 0.8807 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1280 - accuracy: 0.9875 - val_loss: 0.8795 - val_accuracy: 0.5500\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1327 - accuracy: 0.9875 - val_loss: 0.8738 - val_accuracy: 0.5500\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1117 - accuracy: 1.0000 - val_loss: 0.8844 - val_accuracy: 0.5500\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1087 - accuracy: 1.0000 - val_loss: 0.9045 - val_accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1060 - accuracy: 0.9875 - val_loss: 0.9083 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1209 - accuracy: 1.0000 - val_loss: 0.9158 - val_accuracy: 0.5500\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1195 - accuracy: 0.9875 - val_loss: 0.9272 - val_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0851 - accuracy: 1.0000 - val_loss: 0.9547 - val_accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0915 - accuracy: 1.0000 - val_loss: 0.9720 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1068 - accuracy: 0.9750 - val_loss: 0.9538 - val_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0854 - accuracy: 1.0000 - val_loss: 0.9691 - val_accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0998 - accuracy: 1.0000 - val_loss: 0.9628 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 0.9673 - val_accuracy: 0.5500\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.9870 - val_accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.9949 - val_accuracy: 0.5500\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.9995 - val_accuracy: 0.5500\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 1.0162 - val_accuracy: 0.5500\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 1.0284 - val_accuracy: 0.5500\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 1.0428 - val_accuracy: 0.5500\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 1.0507 - val_accuracy: 0.5500\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 1.0518 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 1.0541 - val_accuracy: 0.5500\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 1.0573 - val_accuracy: 0.5500\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 1.0639 - val_accuracy: 0.5500\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 1.0713 - val_accuracy: 0.5500\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 1.0802 - val_accuracy: 0.5500\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 1.0853 - val_accuracy: 0.5500\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 1.0890 - val_accuracy: 0.6000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 1.0937 - val_accuracy: 0.5500\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 1.0981 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 1.1029 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 1.1091 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 1.1168 - val_accuracy: 0.5500\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0309 - accuracy: 0.9875 - val_loss: 1.1229 - val_accuracy: 0.5500\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 1.1282 - val_accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 1.1335 - val_accuracy: 0.5500\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.1474 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.1535 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 1.1457 - val_accuracy: 0.5500\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 1.1436 - val_accuracy: 0.5500\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 1.1461 - val_accuracy: 0.5500\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.1517 - val_accuracy: 0.5500\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 1.1561 - val_accuracy: 0.5500\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.1612 - val_accuracy: 0.5500\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 1.1691 - val_accuracy: 0.5500\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 1.1722 - val_accuracy: 0.5500\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.1790 - val_accuracy: 0.5500\n",
      "Final Training Loss: 0.0175\n",
      "Final Training Accuracy: 1.0000\n",
      "Final Validation Loss: 1.1790\n",
      "Final Validation Accuracy: 0.5500\n",
      "Model training complete and saved as cnn_model.h5.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, save_model\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def configure_cnn_model(input_length, num_features):\n",
    "    \"\"\"Configures a basic one-dimensional Convolutional Neural Network (CNN).\"\"\"\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(input_length, num_features)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def prepare_and_train_model(input_length=12, num_features=20, epochs=100, batch_size=32, test_split=0.2, sample_size=100):\n",
    "    \"\"\"\n",
    "    Generates synthetic data and uses it to train the CNN model.\n",
    "    This method streamlines the process of dataset creation and model training.\n",
    "    \"\"\"\n",
    "    # Generating synthetic data\n",
    "    features = np.random.rand(sample_size, input_length, num_features)\n",
    "    labels = np.random.randint(2, size=(sample_size,))\n",
    "\n",
    "    # Splitting the dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=test_split, random_state=42)\n",
    "    \n",
    "    # Setting up the CNN model\n",
    "    model = configure_cnn_model(input_length, num_features)\n",
    "    \n",
    "    # Training the model with the synthetic data\n",
    "    training_summary = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), verbose=1)\n",
    "    \n",
    "    # Displaying training and validation results\n",
    "    print(f\"Final Training Loss: {training_summary.history['loss'][-1]:.4f}\")\n",
    "    print(f\"Final Training Accuracy: {training_summary.history['accuracy'][-1]:.4f}\")\n",
    "    print(f\"Final Validation Loss: {training_summary.history['val_loss'][-1]:.4f}\")\n",
    "    print(f\"Final Validation Accuracy: {training_summary.history['val_accuracy'][-1]:.4f}\")\n",
    "    \n",
    "    # Saving the trained model to a file\n",
    "    model.save('cnn_model.h5')\n",
    "    print(\"Model training complete and saved as cnn_model.h5.\")\n",
    "\n",
    "# Running the training process with predefined settings\n",
    "prepare_and_train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fa8fd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n",
      "    Data Point  Estimated Fraud Risk\n",
      "40          41              0.741387\n",
      "41          42              0.570967\n",
      "42          43              0.004289\n",
      "43          44              0.591796\n",
      "44          45              0.855879\n",
      "45          46              0.785878\n",
      "46          47              0.332442\n",
      "47          48              0.989006\n",
      "48          49              0.105162\n",
      "49          50              0.658722\n",
      "50          51              0.387856\n",
      "51          52              0.436683\n",
      "52          53              0.210660\n",
      "53          54              0.870550\n",
      "54          55              0.742514\n",
      "55          56              0.477115\n",
      "56          57              0.974201\n",
      "57          58              0.127451\n",
      "58          59              0.191252\n",
      "59          60              0.061510\n",
      "60          61              0.488791\n",
      "61          62              0.588295\n",
      "62          63              0.018867\n",
      "63          64              0.087880\n",
      "64          65              0.722675\n",
      "65          66              0.711886\n",
      "66          67              0.020974\n",
      "67          68              0.624401\n",
      "68          69              0.989513\n",
      "69          70              0.531840\n",
      "70          71              0.891923\n",
      "71          72              0.349558\n",
      "72          73              0.083695\n",
      "73          74              0.881703\n",
      "74          75              0.942918\n",
      "75          76              0.598563\n",
      "76          77              0.494727\n",
      "77          78              0.773838\n",
      "78          79              0.879967\n",
      "79          80              0.182773\n",
      "80          81              0.095420\n",
      "81          82              0.521920\n",
      "82          83              0.953380\n",
      "83          84              0.198126\n",
      "84          85              0.735735\n",
      "85          86              0.093846\n",
      "86          87              0.990443\n",
      "87          88              0.733271\n",
      "88          89              0.081290\n",
      "89          90              0.935739\n",
      "90          91              0.019928\n",
      "91          92              0.895549\n",
      "92          93              0.997810\n",
      "93          94              0.843636\n",
      "94          95              0.989873\n",
      "95          96              0.940825\n",
      "96          97              0.965971\n",
      "97          98              0.388668\n",
      "98          99              0.893830\n",
      "99         100              0.988144\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_fraud_risk(model_file, input_data):\n",
    "    \"\"\"\n",
    "    This function opens a machine learning model that's been trained to identify fraud.\n",
    "    It examines each data point provided to estimate its likelihood of being fraudulent.\n",
    "    The results are organized into a table, making it easier to understand the model's assessments.\n",
    "    \n",
    "    Arguments:\n",
    "    - model_file: The file location of the machine learning model.\n",
    "    - input_data: Data for the model to evaluate, formatted as an array. This array must be prepared in the same way as the data used for training the model.\n",
    "    \n",
    "    Outcome:\n",
    "    - A table (DataFrame) showing each data point with its calculated fraud risk.\n",
    "    \"\"\"\n",
    "    # Opening the specified machine learning model\n",
    "    trained_model = load_model(model_file)\n",
    "    \n",
    "    # Using the model to estimate fraud risk for the provided data\n",
    "    estimated_risk = trained_model.predict(input_data).flatten()\n",
    "    \n",
    "    # Organizing the risk estimates into a table\n",
    "    risk_table = pd.DataFrame({\n",
    "        'Data Point': np.arange(1, len(estimated_risk) + 1), \n",
    "        'Estimated Fraud Risk': estimated_risk\n",
    "    })\n",
    "    \n",
    "    # Sharing the organized table\n",
    "    return risk_table\n",
    "\n",
    "# For the purpose of demonstration, synthetic data resembling the model's training format is created\n",
    "sample_size = 100  # Suppose there are 100 data points to evaluate\n",
    "sequence_length = 12  # Each data point is a sequence of 12 steps\n",
    "feature_count = 20  # Each step in the sequence has 20 features\n",
    "simulated_data = np.random.rand(sample_size, sequence_length, feature_count)\n",
    "\n",
    "# Predicting fraud risk with the provided model file and simulated data\n",
    "fraud_risk_table = evaluate_fraud_risk('cnn_model.h5', simulated_data)\n",
    "# Showing the first 40 data points and their estimated fraud risk for clarity\n",
    "print(fraud_risk_table.tail(60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66c6ff6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_fraud_risk_with_visualization(model_file, input_data):\n",
    "    \"\"\"\n",
    "    This function opens a machine learning model that's been trained to identify fraud.\n",
    "    It examines each data point provided to estimate its likelihood of being fraudulent.\n",
    "    The results are organized into a table and visualized, making it easier to understand the model's assessments.\n",
    "    \n",
    "    Arguments:\n",
    "    - model_file: The file location of the machine learning model.\n",
    "    - input_data: Data for the model to evaluate, formatted as an array. This array must be prepared in the same way as the data used for training the model.\n",
    "    \n",
    "    Outcome:\n",
    "    - A table (DataFrame) showing each data point with its calculated fraud risk.\n",
    "    - A visualization of the estimated fraud risk scores.\n",
    "    \"\"\"\n",
    "    # Opening the specified machine learning model\n",
    "    trained_model = load_model(model_file)\n",
    "    \n",
    "    # Using the model to estimate fraud risk for the provided data\n",
    "    estimated_risk = trained_model.predict(input_data).flatten()\n",
    "    \n",
    "    # Organizing the risk estimates into a table\n",
    "    risk_table = pd.DataFrame({\n",
    "        'Data Point': np.arange(1, len(estimated_risk) + 1), \n",
    "        'Estimated Fraud Risk': estimated_risk\n",
    "    })\n",
    "    \n",
    "    # Visualizing the risk scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(risk_table['Data Point'].values, risk_table['Estimated Fraud Risk'].values, marker='o', linestyle='-', color='red')\n",
    "    plt.title('Estimated Fraud Risk Scores')\n",
    "    plt.xlabel('Data Point')\n",
    "    plt.ylabel('Estimated Fraud Risk')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Sharing the organized table\n",
    "    return risk_table\n",
    "\n",
    "# For the purpose of demonstration, synthetic data resembling the model's training format is created\n",
    "# sample_size = 100  # Suppose there are 100 data points to evaluate\n",
    "# sequence_length = 12  # Each data point is a sequence of 12 steps\n",
    "# feature_count = 20  # Each step in the sequence has 20 features\n",
    "# simulated_data = np.random.rand(sample_size, sequence_length, feature_count)\n",
    "\n",
    "# Predicting fraud risk with the provided model file and simulated data\n",
    "fraud_risk_table_with_viz = evaluate_fraud_risk_with_visualization('cnn_model.h5', simulated_data)\n",
    "# Note: You would replace 'cnn_model.h5' with the actual path to your CNN model file,\n",
    "# and ensure `simulated_data` is prepared correctly for your model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c09725",
   "metadata": {},
   "source": [
    "### Design and Training - RNN Model\n",
    "This section outlines the steps for designing and training a Recurrent Neural Network (RNN) model, focusing on Long Short-Term Memory (LSTM) layers. RNNs are particularly suited for sequential or time-series data due to their ability to retain information from previous inputs in the sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3db96922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dee429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_rnn_model(input_length, num_features):\n",
    "    \"\"\"Configures a basic Recurrent Neural Network (RNN) using LSTM layers.\"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(32, return_sequences=True, input_shape=(input_length, num_features)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "530ec28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 3s 260ms/step - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6802 - val_accuracy: 0.6000\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6896 - accuracy: 0.5500 - val_loss: 0.6763 - val_accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6858 - accuracy: 0.5625 - val_loss: 0.6751 - val_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6869 - accuracy: 0.5875 - val_loss: 0.6745 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6920 - accuracy: 0.5500 - val_loss: 0.6741 - val_accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6807 - accuracy: 0.5875 - val_loss: 0.6751 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6935 - accuracy: 0.5500 - val_loss: 0.6753 - val_accuracy: 0.6000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6770 - accuracy: 0.5375 - val_loss: 0.6759 - val_accuracy: 0.6000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6863 - accuracy: 0.5500 - val_loss: 0.6750 - val_accuracy: 0.6000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6845 - accuracy: 0.5500 - val_loss: 0.6727 - val_accuracy: 0.6000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6908 - accuracy: 0.5375 - val_loss: 0.6711 - val_accuracy: 0.6000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6738 - accuracy: 0.5375 - val_loss: 0.6707 - val_accuracy: 0.6000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6791 - accuracy: 0.5750 - val_loss: 0.6720 - val_accuracy: 0.6000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6847 - accuracy: 0.5500 - val_loss: 0.6770 - val_accuracy: 0.6000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6870 - accuracy: 0.5625 - val_loss: 0.6797 - val_accuracy: 0.6000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6899 - accuracy: 0.6250 - val_loss: 0.6781 - val_accuracy: 0.6000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6888 - accuracy: 0.4625 - val_loss: 0.6753 - val_accuracy: 0.6000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6905 - accuracy: 0.5125 - val_loss: 0.6743 - val_accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6859 - accuracy: 0.5500 - val_loss: 0.6713 - val_accuracy: 0.6000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6784 - accuracy: 0.5750 - val_loss: 0.6708 - val_accuracy: 0.6000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6883 - accuracy: 0.5500 - val_loss: 0.6706 - val_accuracy: 0.6000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6817 - accuracy: 0.5625 - val_loss: 0.6722 - val_accuracy: 0.6000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6821 - accuracy: 0.5250 - val_loss: 0.6748 - val_accuracy: 0.6000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6781 - accuracy: 0.6000 - val_loss: 0.6784 - val_accuracy: 0.6500\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6906 - accuracy: 0.5625 - val_loss: 0.6758 - val_accuracy: 0.6000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6854 - accuracy: 0.5750 - val_loss: 0.6728 - val_accuracy: 0.6000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6677 - accuracy: 0.5625 - val_loss: 0.6720 - val_accuracy: 0.6000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6831 - accuracy: 0.5750 - val_loss: 0.6720 - val_accuracy: 0.6000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6712 - accuracy: 0.5625 - val_loss: 0.6698 - val_accuracy: 0.6000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6682 - accuracy: 0.5875 - val_loss: 0.6716 - val_accuracy: 0.6500\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6731 - accuracy: 0.6000 - val_loss: 0.6706 - val_accuracy: 0.6000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6710 - accuracy: 0.5625 - val_loss: 0.6676 - val_accuracy: 0.6000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6540 - accuracy: 0.5750 - val_loss: 0.6659 - val_accuracy: 0.5500\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6446 - accuracy: 0.5500 - val_loss: 0.6672 - val_accuracy: 0.6000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6486 - accuracy: 0.6250 - val_loss: 0.6644 - val_accuracy: 0.6000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.6591 - accuracy: 0.6000 - val_loss: 0.6646 - val_accuracy: 0.5500\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6346 - accuracy: 0.6375 - val_loss: 0.6689 - val_accuracy: 0.6000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6381 - accuracy: 0.6875 - val_loss: 0.6602 - val_accuracy: 0.6000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6232 - accuracy: 0.6500 - val_loss: 0.6591 - val_accuracy: 0.6000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5979 - accuracy: 0.6875 - val_loss: 0.6526 - val_accuracy: 0.6500\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6329 - accuracy: 0.6250 - val_loss: 0.6475 - val_accuracy: 0.6000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6202 - accuracy: 0.6375 - val_loss: 0.6774 - val_accuracy: 0.6000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6171 - accuracy: 0.6875 - val_loss: 0.6406 - val_accuracy: 0.6000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6078 - accuracy: 0.6500 - val_loss: 0.6377 - val_accuracy: 0.5500\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5714 - accuracy: 0.6625 - val_loss: 0.6731 - val_accuracy: 0.6000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6373 - accuracy: 0.7000 - val_loss: 0.6373 - val_accuracy: 0.6000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5789 - accuracy: 0.7125 - val_loss: 0.6366 - val_accuracy: 0.5500\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5847 - accuracy: 0.7125 - val_loss: 0.6368 - val_accuracy: 0.6000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5368 - accuracy: 0.7625 - val_loss: 0.6359 - val_accuracy: 0.6000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5772 - accuracy: 0.7250 - val_loss: 0.6387 - val_accuracy: 0.5500\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5330 - accuracy: 0.7125 - val_loss: 0.6430 - val_accuracy: 0.5500\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5677 - accuracy: 0.7000 - val_loss: 0.6480 - val_accuracy: 0.6000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5103 - accuracy: 0.7625 - val_loss: 0.6513 - val_accuracy: 0.6000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5073 - accuracy: 0.7500 - val_loss: 0.6438 - val_accuracy: 0.6000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4959 - accuracy: 0.7750 - val_loss: 0.6445 - val_accuracy: 0.6000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5229 - accuracy: 0.7375 - val_loss: 0.6471 - val_accuracy: 0.6000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5085 - accuracy: 0.7875 - val_loss: 0.6803 - val_accuracy: 0.6000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5018 - accuracy: 0.7875 - val_loss: 0.6625 - val_accuracy: 0.6000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5463 - accuracy: 0.6875 - val_loss: 0.6764 - val_accuracy: 0.5500\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5472 - accuracy: 0.7625 - val_loss: 0.6928 - val_accuracy: 0.6000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5069 - accuracy: 0.7875 - val_loss: 0.6876 - val_accuracy: 0.6500\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6329 - accuracy: 0.6250 - val_loss: 0.6500 - val_accuracy: 0.6000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4773 - accuracy: 0.8125 - val_loss: 0.7373 - val_accuracy: 0.6000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5741 - accuracy: 0.7375 - val_loss: 0.6688 - val_accuracy: 0.5500\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4741 - accuracy: 0.8125 - val_loss: 0.6379 - val_accuracy: 0.6000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4920 - accuracy: 0.7125 - val_loss: 0.6612 - val_accuracy: 0.5500\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5301 - accuracy: 0.8125 - val_loss: 0.6886 - val_accuracy: 0.6000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5174 - accuracy: 0.8000 - val_loss: 0.6641 - val_accuracy: 0.6000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.4720 - accuracy: 0.7875 - val_loss: 0.6689 - val_accuracy: 0.6000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4497 - accuracy: 0.7750 - val_loss: 0.6857 - val_accuracy: 0.5500\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4388 - accuracy: 0.8000 - val_loss: 0.7004 - val_accuracy: 0.5500\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.4379 - accuracy: 0.8250 - val_loss: 0.7143 - val_accuracy: 0.6000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4564 - accuracy: 0.8375 - val_loss: 0.7053 - val_accuracy: 0.6000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4654 - accuracy: 0.8250 - val_loss: 0.7243 - val_accuracy: 0.6000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4602 - accuracy: 0.8125 - val_loss: 0.7000 - val_accuracy: 0.6000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.4107 - accuracy: 0.8500 - val_loss: 0.6976 - val_accuracy: 0.6500\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4359 - accuracy: 0.8250 - val_loss: 0.7053 - val_accuracy: 0.6000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4247 - accuracy: 0.8375 - val_loss: 0.6820 - val_accuracy: 0.6000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4360 - accuracy: 0.7750 - val_loss: 0.6817 - val_accuracy: 0.6500\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4320 - accuracy: 0.8000 - val_loss: 0.6788 - val_accuracy: 0.6500\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4473 - accuracy: 0.8000 - val_loss: 0.6659 - val_accuracy: 0.6500\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4336 - accuracy: 0.8000 - val_loss: 0.7165 - val_accuracy: 0.6000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4567 - accuracy: 0.7750 - val_loss: 0.7821 - val_accuracy: 0.6500\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4823 - accuracy: 0.7375 - val_loss: 0.6884 - val_accuracy: 0.6000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5237 - accuracy: 0.7000 - val_loss: 0.7431 - val_accuracy: 0.5500\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4308 - accuracy: 0.7875 - val_loss: 0.7543 - val_accuracy: 0.6000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4887 - accuracy: 0.7125 - val_loss: 0.6251 - val_accuracy: 0.7000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.4366 - accuracy: 0.7875 - val_loss: 0.6650 - val_accuracy: 0.6000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4222 - accuracy: 0.8375 - val_loss: 0.6370 - val_accuracy: 0.6000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.3765 - accuracy: 0.8500 - val_loss: 0.6664 - val_accuracy: 0.6000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3605 - accuracy: 0.8875 - val_loss: 0.6351 - val_accuracy: 0.6500\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3458 - accuracy: 0.8750 - val_loss: 0.6389 - val_accuracy: 0.6500\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3151 - accuracy: 0.8750 - val_loss: 0.7347 - val_accuracy: 0.6000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3821 - accuracy: 0.8000 - val_loss: 0.6952 - val_accuracy: 0.6500\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3083 - accuracy: 0.8625 - val_loss: 0.6614 - val_accuracy: 0.7000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.3215 - accuracy: 0.8500 - val_loss: 0.7067 - val_accuracy: 0.6000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3133 - accuracy: 0.8625 - val_loss: 0.6871 - val_accuracy: 0.7000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.2902 - accuracy: 0.8875 - val_loss: 0.7046 - val_accuracy: 0.7000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2572 - accuracy: 0.8875 - val_loss: 0.7768 - val_accuracy: 0.6000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2589 - accuracy: 0.8875 - val_loss: 0.7194 - val_accuracy: 0.7000\n",
      "Final Training Loss: 0.2589\n",
      "Final Training Accuracy: 0.8875\n",
      "Final Validation Loss: 0.7194\n",
      "Final Validation Accuracy: 0.7000\n",
      "Model training complete and saved as rnn_model.h5.\n"
     ]
    }
   ],
   "source": [
    "def prepare_and_train_rnn_model(input_length=12, num_features=20, epochs=100, batch_size=32, test_split=0.2, sample_size=100):\n",
    "    \"\"\"\n",
    "    Generates synthetic data and uses it to train the RNN model.\n",
    "    \"\"\"\n",
    "    # Generating synthetic data\n",
    "    features = np.random.rand(sample_size, input_length, num_features)\n",
    "    labels = np.random.randint(2, size=(sample_size,))\n",
    "\n",
    "    # Splitting the dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=test_split, random_state=42)\n",
    "    \n",
    "    # Setting up the RNN model\n",
    "    model = configure_rnn_model(input_length, num_features)\n",
    "    \n",
    "    # Training the model with the synthetic data\n",
    "    training_summary = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), verbose=1)\n",
    "    \n",
    "    # Displaying training and validation results\n",
    "    print(f\"Final Training Loss: {training_summary.history['loss'][-1]:.4f}\")\n",
    "    print(f\"Final Training Accuracy: {training_summary.history['accuracy'][-1]:.4f}\")\n",
    "    print(f\"Final Validation Loss: {training_summary.history['val_loss'][-1]:.4f}\")\n",
    "    print(f\"Final Validation Accuracy: {training_summary.history['val_accuracy'][-1]:.4f}\")\n",
    "    \n",
    "    # Saving the trained model to a file\n",
    "    model.save('rnn_model.h5')\n",
    "    print(\"Model training complete and saved as rnn_model.h5.\")\n",
    "\n",
    "# You can now run the training process with:\n",
    "prepare_and_train_rnn_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af4bcf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n",
      "    Data Point  Estimated Risk Score\n",
      "90          91              0.345969\n",
      "91          92              0.147174\n",
      "92          93              0.100349\n",
      "93          94              0.621105\n",
      "94          95              0.819477\n",
      "95          96              0.258739\n",
      "96          97              0.294540\n",
      "97          98              0.188347\n",
      "98          99              0.168209\n",
      "99         100              0.985104\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_email_risk(model_file, input_data):\n",
    "    \"\"\"\n",
    "    This function opens a machine learning model that's been trained to identify high-risk emails,\n",
    "    such as potential spam or phishing attempts. It examines each data point provided to estimate\n",
    "    its likelihood of being high-risk. The results are organized into a table, making it easier to\n",
    "    understand the model's assessments.\n",
    "    \n",
    "    Arguments:\n",
    "    - model_file: The file location of the machine learning model.\n",
    "    - input_data: Data for the model to evaluate, formatted as an array. This array must be prepared\n",
    "      in the same way as the data used for training the model.\n",
    "    \n",
    "    Outcome:\n",
    "    - A table (DataFrame) showing each data point with its calculated risk score.\n",
    "    \"\"\"\n",
    "    # Opening the specified machine learning model\n",
    "    trained_model = load_model(model_file)\n",
    "    \n",
    "    # Using the model to estimate email risk for the provided data\n",
    "    estimated_risk = trained_model.predict(input_data).flatten()\n",
    "    \n",
    "    # Organizing the risk estimates into a table\n",
    "    risk_table = pd.DataFrame({\n",
    "        'Data Point': np.arange(1, len(estimated_risk) + 1),\n",
    "        'Estimated Risk Score': estimated_risk\n",
    "    })\n",
    "    \n",
    "    # Sharing the organized table\n",
    "    return risk_table\n",
    "\n",
    "# Assuming `simulated_data` matches the RNN model's expected input format\n",
    "# For demonstration purposes, creating synthetic data resembling the model's training format\n",
    "sample_size = 100  # Suppose there are 100 data points to evaluate\n",
    "sequence_length = 12  # Each data point is a sequence of 12 steps\n",
    "feature_count = 20  # Each step in the sequence has 20 features\n",
    "simulated_data = np.random.rand(sample_size, sequence_length, feature_count)\n",
    "\n",
    "# Predicting email risk with the provided RNN model file and simulated data\n",
    "email_risk_table = evaluate_email_risk('rnn_model.h5', simulated_data)\n",
    "\n",
    "# Showing the last 60 data points and their estimated risk score for clarity\n",
    "print(email_risk_table.tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a4e4887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_email_risk_with_visualization(model_file, input_data):\n",
    "    \"\"\"\n",
    "    This function opens a machine learning model, uses it to estimate the risk of\n",
    "    each provided data point being high-risk, and visualizes these estimates.\n",
    "    \n",
    "    Arguments:\n",
    "    - model_file: The file location of the machine learning model.\n",
    "    - input_data: Data for the model to evaluate, formatted as an array.\n",
    "    \n",
    "    Outcome:\n",
    "    - A visualization of each data point's estimated risk score.\n",
    "    \"\"\"\n",
    "    # Opening the specified machine learning model\n",
    "    trained_model = load_model(model_file)\n",
    "    \n",
    "    # Using the model to estimate email risk for the provided data\n",
    "    estimated_risk = trained_model.predict(input_data).flatten()\n",
    "    \n",
    "    # Organizing the risk estimates into a table\n",
    "    risk_table = pd.DataFrame({\n",
    "        'Data Point': np.arange(1, len(estimated_risk) + 1),\n",
    "        'Estimated Risk Score': estimated_risk\n",
    "    })\n",
    "    \n",
    "    # Visualizing the risk scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(risk_table['Data Point'].values, risk_table['Estimated Risk Score'].values, marker='o', linestyle='-', color='blue')\n",
    "    plt.title('Estimated Email Risk Scores')\n",
    "    plt.xlabel('Data Point')\n",
    "    plt.ylabel('Estimated Risk Score')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Sharing the organized table\n",
    "    return risk_table\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `simulated_data` is already defined and matches the model's input format\n",
    "email_risk_table_with_viz = evaluate_email_risk_with_visualization('rnn_model.h5', simulated_data)\n",
    "# Note: You would replace 'rnn_model.h5' with the actual path to your RNN model file,\n",
    "# and ensure `simulated_data` is prepared correctly for your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fddbd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step\n",
      "    Data Point  Risk Score\n",
      "0            1    0.893600\n",
      "1            2    0.995991\n",
      "3            4    0.984348\n",
      "4            5    0.997825\n",
      "5            6    0.999112\n",
      "7            8    0.992386\n",
      "15          16    0.997757\n",
      "16          17    0.975045\n",
      "18          19    0.861989\n",
      "21          22    0.989755\n",
      "24          25    0.995261\n",
      "32          33    0.998896\n",
      "39          40    0.993671\n",
      "41          42    0.871940\n",
      "43          44    0.800342\n",
      "45          46    0.810138\n",
      "47          48    0.998703\n",
      "48          49    0.998188\n",
      "54          55    0.998628\n",
      "58          59    0.994618\n",
      "60          61    0.991922\n",
      "65          66    0.998212\n",
      "68          69    0.995874\n",
      "69          70    0.990676\n",
      "70          71    0.983123\n",
      "72          73    0.990098\n",
      "75          76    0.996022\n",
      "78          79    0.963340\n",
      "79          80    0.949108\n",
      "82          83    0.992029\n",
      "83          84    0.858982\n",
      "87          88    0.822909\n",
      "88          89    0.947349\n",
      "89          90    0.952153\n",
      "90          91    0.998651\n",
      "94          95    0.928322\n",
      "96          97    0.998276\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "\n",
    "def evaluate_and_filter_high_risk(model_file, input_data, risk_threshold=0.8):\n",
    "    \"\"\"\n",
    "    This function loads a trained machine learning model, predicts the risk scores\n",
    "    for the provided email data, and filters to only show high-risk scores above\n",
    "    a certain threshold.\n",
    "    \n",
    "    Arguments:\n",
    "    - model_file: The file path to the trained machine learning model.\n",
    "    - input_data: The data on which to perform the risk assessment.\n",
    "    - risk_threshold: The cutoff value above which a score is considered high risk.\n",
    "    \n",
    "    Returns:\n",
    "    - A DataFrame containing only the high-risk scores and their corresponding data points.\n",
    "    \"\"\"\n",
    "    # Load the trained machine learning model\n",
    "    model = load_model(model_file)\n",
    "    \n",
    "    # Predict the risk scores using the model\n",
    "    risk_scores = model.predict(input_data).flatten()\n",
    "    \n",
    "    # Create a DataFrame of the results\n",
    "    risk_df = pd.DataFrame({\n",
    "        'Data Point': np.arange(1, len(risk_scores) + 1),\n",
    "        'Risk Score': risk_scores\n",
    "    })\n",
    "    \n",
    "    # Filter the DataFrame to only include high-risk scores\n",
    "    high_risk_df = risk_df[risk_df['Risk Score'] > risk_threshold]\n",
    "    \n",
    "    return high_risk_df\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `simulated_data` is available and properly formatted\n",
    "high_risk_emails = evaluate_and_filter_high_risk('rnn_model.h5', simulated_data)\n",
    "print(high_risk_emails)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fa0fbd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n",
      "   Data Point  Risk Score                Email Content\n",
      "0          16    0.997757  Email content not available\n",
      "1          39    0.145421  Email content not available\n",
      "2          44    0.800342  Email content not available\n",
      "3          50    0.121466  Email content not available\n",
      "4          59    0.994618  Email content not available\n",
      "5          86    0.131154  Email content not available\n",
      "6          89    0.947349  Email content not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/02 16:32:06 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 1195927 ms exceeds timeout 120000 ms\n",
      "24/04/02 16:32:06 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:39825\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/04/02 16:32:07 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 56224)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 281, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 253, in poll\n",
      "    if func():\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 257, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/usr/local/spark/python/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "\n",
    "def retrieve_high_risk_emails(model_file, input_data, emails, data_points):\n",
    "    \"\"\"\n",
    "    Retrieves high-risk emails based on the provided list of data points\n",
    "    considered high risk.\n",
    "    \n",
    "    Arguments:\n",
    "    - model_file: Path to the trained model.\n",
    "    - input_data: Input data the model evaluates.\n",
    "    - emails: List of email contents corresponding to each entry in input_data.\n",
    "    - data_points: Indices of data points flagged as high risk.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with data points, their risk scores, and email contents for high-risk emails.\n",
    "    \"\"\"\n",
    "    model = load_model(model_file)\n",
    "    risk_scores = model.predict(input_data).flatten()\n",
    "    \n",
    "    high_risk_emails = {\n",
    "        'Data Point': [],\n",
    "        'Risk Score': [],\n",
    "        'Email Content': []\n",
    "    }\n",
    "    \n",
    "    for i in data_points:\n",
    "        if i-1 < len(risk_scores):\n",
    "            high_risk_emails['Data Point'].append(i)\n",
    "            high_risk_emails['Risk Score'].append(risk_scores[i-1])\n",
    "            high_risk_emails['Email Content'].append(emails[i-1] if i-1 < len(emails) else \"Email content not available\")\n",
    "    \n",
    "    return pd.DataFrame(high_risk_emails)\n",
    "\n",
    "# Assuming `simulated_data` is your model's input and `high_risk_data_points` contains indices of high-risk emails.\n",
    "high_risk_data_points = [16, 39, 44, 50, 59, 86, 89]  # Adjust as per your findings\n",
    "email_contents = [\"Email content 1\", \"Email content 2\", \"...\"]  # Fill with actual email contents\n",
    "\n",
    "# Ensure `email_contents` has an entry for each item in `simulated_data`\n",
    "high_risk_emails_df = retrieve_high_risk_emails('rnn_model.h5', simulated_data, email_contents, high_risk_data_points)\n",
    "print(high_risk_emails_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
